# Live Orientation Display

## Background
- The relative orientation of an object, such as a CubeSat, can be computed through inertial vector measurements (magnetic field, acceleration, angular rate).
- Due to the noise, disturbances and drift of measurements, sensor data must be fused using filtering techniques (such as the complimentary filter or Kalman Filter).
- Filtering is critical to attitude determination algorithms of CubeSats, which enables accurate attitude control
- This project is a gateway to learn about ADCS algorithms while making something visually epic in the process!

## Project Objectives
- Learn how sensor filtering techniques work to provide more accurate estimations of a system's state
- Learn how to parameterize an Object's orientation using sensor measurements
- Process real-time data by interfacing with an inertial measurement unit (IMU) and microcontroller
- Program a Live Orientation Display using attitude algorithms and filtering techniques to improve accuracy

## Resources to get you started
- [ Understanding Sensor Fusion and Tracking, Part 2: Fusing a Mag, Accel, & Gyro Estimate](https://www.youtube.com/watch?v=0rlvvYgmTvI)
- [Estimating phone orientation with Sensor Fusion](https://au.mathworks.com/help/nav/ug/estimate-phone-orientation-using-sensor-fusion.html)
- [Sensor fusion for orientation estimation](https://www.youtube.com/watch?v=UZsxFpjmdAs)
- [How To Track Orientation with Arduino | ADXL345 Accelerometer Tutorial](https://www.youtube.com/watch?v=KMhbV1p3MWk)

Please reach out to a HR member to get the sensors and microcontroller when you need it.

![image](https://github.com/user-attachments/assets/0b561cfd-33aa-4c7a-86bd-3f2b3a1fc202)
